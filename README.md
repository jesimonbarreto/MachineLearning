# Machine Learning 
### Trabalho Prático - UFMG - ICEX -  DCC
### Jesimon Barreto
#### Trabalho 1 
Neste trabalho Comparação entre seis métodos de classificação: Naive
Bayes, Decision Tree, k-Nearest Neighbors, Support Vector Machines, Random Forest e Gradient
Tree Boosting. Além disto deverá realizar os experimentos listados abaixo específicos para cada
método. 
A avaliação dos métodos deverá ser feito usando a acurácia e validação cruzada k-fold com k igual a 5.
• Naive Bayes: Apenas um experimento para servir de baseline
• Decision Tree: Variar a altura máxima da árvore (incluindo permitir altura ilimitada) e mostrar os resultados graficamente
• SVM: Avaliar os kernels linear, sigmoid, polinomial e RBF
• k-NN: Variar o n´umero k de vizinhos e mostrar os resultados graficamente
• Random Forest: Variar o n´umero de ´arvores e mostrar os resultados graficamente.
• Gradient Tree Boosting: Variar o n´umero de itera¸c˜oes e mostrar os resultados graficamente.

#### Conjunto de Dados
Kepler Object of Interest (KOI).

#### Trabalho 2
Implementar o processo de Boosting (visto em sala de aula) assumindo um problema de classificação binária com atributos categóricos. Em particular, você deverá realizar os experimentos utilizando o dataset tic-tac-toe, disponível em https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame. Sua avalição deverá seguir a metodologia de validação cruzada com 5 partições. A medida de eficácia a ser considerada é a taxa de erro simples. 
